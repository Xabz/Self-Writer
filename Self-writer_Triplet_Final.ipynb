{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8Cbbfg1gkgt",
        "outputId": "aa309b7a-9d4a-43f0-ab41-1b9d03795b0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 21.8 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 5.0 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import glob\n",
        "import pickle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "%matplotlib inline\n",
        "\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.losses import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras import *\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "import IPython.display as ipd\n",
        "from IPython.core.display import display, clear_output\n",
        "\n",
        "\n",
        "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.manifold import TSNE\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "!pip install -q -U tensorflow-addons\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Svzy5-1cPiGa",
        "outputId": "02c20605-1f4a-4c7c-c464-6038e11eed22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVWR1xVwgoHw",
        "outputId": "c974ffbe-98c6-4244-deed-fd85257fe4e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded\n",
            "unziped\n",
            "Zip removed\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists('./IAM Dataset'):\n",
        "    ret = os.system(\"cp '/content/drive/MyDrive/Dataset/IAM_line_images.zip' '/content/IAM_Handwritten_images.zip'\")\n",
        "    ret = os.system(\"cp '/content/drive/MyDrive/Dataset/IAM_line_labels.zip' '/content/IAM_Handwritten_labels.zip'\")\n",
        "\n",
        "    if ret == 0:  print(\"Data loaded\")\n",
        "    os.system(\"unzip -qq '/content/IAM_Handwritten_images.zip'\")\n",
        "    os.system(\"unzip -qq '/content/IAM_Handwritten_labels.zip'\")\n",
        "    print('unziped')\n",
        "\n",
        "    !rm IAM_Handwritten_images.zip\n",
        "    !rm IAM_Handwritten_labels.zip\n",
        "    print('Zip removed')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6M1we6xgyP8"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "# For image drawing\n",
        "from PIL import Image, ImageDraw, ImageFont, ImageEnhance\n",
        "\n",
        "def change_contrast(img, level):\n",
        "    # Input is a Image type\n",
        "    # use Image.fromarray() on numpy\n",
        "    factor = (259 * (level + 255)) / (255 * (259 - level))\n",
        "    def contrast(c):\n",
        "        return 128 + factor * (c - 128)\n",
        "    return img.point(contrast)\n",
        "\n",
        "\n",
        "def change_sharpness(img, level):\n",
        "    enhancer = ImageEnhance.Sharpness(img)\n",
        "    img = enhancer.enhance(level)\n",
        "    return img\n",
        "\n",
        "\n",
        "def adjust(img, blevel, slevel, clevel, colevel):\n",
        "    # brightness\n",
        "    benhance = ImageEnhance.Brightness(img)\n",
        "    img = benhance.enhance(blevel)\n",
        "    # sharpness\n",
        "    img = change_sharpness(img, slevel)\n",
        "    # contrast\n",
        "    img = change_contrast(img, clevel)\n",
        "    # color\n",
        "    cenhance = ImageEnhance.Color(img)\n",
        "    img = cenhance.enhance(colevel)\n",
        "    return img\n",
        "\n",
        "\n",
        "def improveImage(img_dir):\n",
        "    img = cv2.imread(img_dir, -1)\n",
        "    rgb_planes = cv2.split(img)\n",
        "\n",
        "    result_planes = []\n",
        "    result_norm_planes = []\n",
        "    for plane in rgb_planes:\n",
        "        dilated_img = cv2.dilate(plane, np.ones((7,7), np.uint8))\n",
        "        bg_img = cv2.medianBlur(dilated_img, 21)\n",
        "        diff_img = 255 - cv2.absdiff(plane, bg_img)\n",
        "        norm_img = cv2.normalize(diff_img, None, alpha=0,\n",
        "                                 beta=255, norm_type=cv2.NORM_MINMAX,\n",
        "                                 dtype=cv2.CV_8UC1)\n",
        "\n",
        "        result_planes.append(diff_img)\n",
        "        result_norm_planes.append(norm_img)\n",
        "\n",
        "    result = cv2.merge(result_planes)\n",
        "    result_norm = cv2.merge(result_norm_planes)\n",
        "    return result_norm\n",
        "\n",
        "\n",
        "def convert_image(image_dir):\n",
        "    img = improveImage(image_dir)\n",
        "    img = adjust(Image.fromarray(img),\n",
        "                  blevel=0.7, slevel=1, clevel=255,\n",
        "                  colevel=1)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763,
          "referenced_widgets": [
            "7b04f9ba083e40e9959ab7991855b7bb",
            "399717baf4564928bdff876a69f5e9d1",
            "8f418fbb15d840cbb9a99124174ec286",
            "52b1cfbc85524003b37ac1d58db01f23",
            "be09a1424f214254a1164d5ac15c25cd",
            "86180fd221cf4c1bbdba2045b5ee8a0d",
            "3f6b1f19800d44e182e6a98e7ff982df",
            "559e1b12592a45f294ebf34dd3f7157b",
            "d8b78b32a9e141fea1114a9dbe52f39e",
            "7bb382e667fe4e7e882d6287d65eab74",
            "b679fe5c52b143a1916bf5dd10102583"
          ]
        },
        "id": "eNlZRwjjg4j3",
        "outputId": "66078bfe-17cd-4bb7-afc7-6e64fb53dd95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'000': 59, '001': 2, '002': 1, '003': 2, '004': 1, '005': 2, '006': 1, '007': 2, '008': 2, '009': 2, '010': 2, '011': 2, '012': 2, '013': 3, '014': 2, '015': 1, '016': 3, '017': 3, '018': 2, '019': 3, '020': 1, '021': 1, '022': 1, '023': 1, '024': 1, '025': 5, '026': 5, '027': 1, '028': 1, '029': 1, '030': 1, '031': 1, '032': 1, '033': 1, '034': 1, '035': 1, '036': 1, '037': 5, '038': 1, '039': 1, '040': 1, '041': 1, '042': 1, '043': 1, '044': 1, '045': 1, '046': 1, '047': 1, '048': 1, '049': 1, '050': 1, '051': 1, '052': 1, '053': 1, '054': 1, '055': 1, '056': 1, '058': 4, '059': 4, '060': 4, '061': 4, '062': 3, '063': 3, '064': 4, '065': 2, '066': 2, '067': 1, '068': 1, '069': 1, '070': 1, '071': 1, '072': 1, '073': 1, '074': 1, '075': 1, '076': 1, '077': 1, '078': 1, '079': 1, '080': 1, '081': 2, '082': 1, '083': 1, '084': 2, '085': 6, '086': 1, '087': 3, '088': 3, '089': 3, '090': 3, '091': 2, '092': 3, '093': 3, '094': 3, '095': 2, '096': 1, '097': 1, '098': 1, '099': 1, '100': 1, '102': 2, '103': 1, '104': 1, '105': 1, '106': 1, '107': 4, '108': 4, '109': 4, '110': 4, '111': 4, '112': 4, '113': 4, '114': 4, '115': 1, '116': 1, '117': 4, '118': 7, '119': 2, '120': 1, '121': 2, '122': 1, '123': 5, '124': 4, '125': 5, '126': 5, '127': 3, '128': 5, '129': 4, '130': 5, '131': 4, '132': 4, '133': 5, '134': 2, '135': 2, '136': 1, '137': 1, '138': 1, '139': 2, '140': 2, '141': 1, '142': 1, '143': 1, '144': 1, '145': 1, '146': 1, '147': 1, '148': 1, '149': 1, '150': 10, '151': 10, '152': 10, '153': 10, '154': 10, '155': 9, '156': 1, '157': 2, '158': 3, '159': 2, '160': 2, '161': 2, '162': 2, '163': 2, '164': 2, '165': 2, '166': 2, '167': 1, '168': 2, '169': 2, '170': 2, '171': 2, '172': 2, '173': 5, '174': 5, '175': 2, '176': 1, '177': 2, '178': 2, '179': 2, '180': 2, '181': 3, '182': 1, '183': 1, '184': 2, '185': 2, '186': 2, '187': 2, '188': 2, '189': 1, '190': 2, '191': 1, '192': 2, '193': 4, '194': 2, '195': 2, '196': 1, '197': 2, '198': 2, '199': 4, '200': 1, '201': 1, '202': 5, '203': 5, '204': 5, '205': 5, '206': 5, '207': 5, '208': 5, '209': 7, '210': 2, '211': 2, '212': 3, '213': 3, '214': 2, '215': 2, '216': 2, '217': 3, '218': 1, '219': 1, '220': 1, '221': 1, '222': 1, '223': 1, '224': 1, '225': 1, '226': 1, '227': 1, '228': 1, '229': 1, '230': 2, '231': 2, '232': 2, '233': 2, '234': 2, '235': 2, '236': 1, '237': 2, '238': 1, '239': 4, '240': 2, '241': 4, '242': 3, '243': 3, '244': 1, '245': 1, '246': 4, '247': 5, '248': 5, '249': 1, '250': 2, '251': 1, '252': 1, '253': 1, '254': 2, '255': 1, '256': 2, '257': 1, '258': 1, '259': 2, '260': 1, '261': 1, '262': 1, '263': 1, '264': 1, '265': 1, '266': 1, '267': 1, '268': 1, '269': 1, '270': 1, '272': 3, '273': 5, '274': 5, '275': 2, '276': 2, '277': 2, '278': 2, '279': 2, '280': 2, '281': 2, '282': 2, '283': 2, '285': 5, '286': 4, '287': 5, '288': 5, '289': 5, '290': 1, '291': 4, '292': 5, '293': 5, '294': 4, '295': 2, '296': 3, '297': 3, '298': 3, '299': 3, '300': 3, '301': 2, '302': 1, '303': 1, '304': 1, '305': 1, '307': 1, '308': 1, '309': 1, '310': 1, '312': 1, '313': 1, '314': 1, '315': 7, '316': 1, '317': 1, '318': 1, '319': 1, '320': 2, '321': 2, '322': 1, '323': 1, '324': 2, '325': 2, '326': 1, '327': 1, '328': 2, '329': 2, '330': 4, '331': 1, '332': 8, '333': 9, '334': 9, '336': 9, '337': 9, '338': 9, '339': 9, '340': 9, '341': 9, '342': 9, '343': 9, '344': 9, '345': 9, '346': 9, '347': 9, '348': 9, '335': 8, '349': 9, '350': 4, '351': 5, '352': 5, '353': 5, '354': 5, '355': 5, '356': 2, '357': 3, '359': 1, '360': 1, '361': 1, '362': 1, '363': 1, '364': 2, '365': 1, '366': 1, '367': 1, '368': 1, '369': 1, '370': 1, '371': 1, '372': 1, '373': 1, '375': 1, '376': 1, '377': 1, '378': 1, '379': 2, '380': 2, '382': 2, '383': 2, '384': 10, '385': 5, '386': 5, '387': 5, '388': 3, '389': 5, '390': 5, '391': 5, '392': 4, '393': 5, '394': 2, '395': 1, '396': 1, '397': 1, '398': 1, '399': 1, '400': 1, '401': 1, '402': 1, '403': 2, '405': 2, '404': 1, '407': 1, '408': 2, '409': 2, '410': 1, '411': 1, '412': 1, '413': 1, '414': 2, '415': 7, '416': 1, '417': 1, '418': 1, '419': 1, '420': 2, '421': 1, '422': 1, '423': 1, '424': 1, '425': 1, '426': 1, '427': 1, '428': 1, '429': 1, '430': 1, '431': 1, '432': 1, '433': 1, '434': 1, '435': 1, '436': 1, '439': 2, '406': 1, '440': 1, '441': 1, '442': 2, '443': 2, '444': 2, '445': 2, '446': 2, '447': 2, '448': 2, '449': 2, '450': 2, '451': 2, '452': 2, '453': 2, '454': 5, '455': 5, '456': 5, '457': 1, '458': 3, '459': 1, '460': 1, '461': 1, '462': 1, '463': 1, '464': 1, '465': 1, '466': 1, '467': 1, '468': 1, '469': 1, '470': 1, '471': 1, '472': 1, '473': 1, '474': 1, '475': 1, '476': 1, '477': 1, '478': 1, '479': 1, '480': 2, '481': 2, '482': 2, '483': 2, '484': 2, '485': 1, '486': 2, '487': 2, '488': 2, '489': 2, '490': 2, '491': 2, '492': 2, '493': 2, '494': 2, '495': 3, '496': 4, '497': 4, '498': 5, '499': 1, '500': 1, '501': 1, '502': 1, '503': 1, '504': 1, '505': 1, '506': 1, '508': 1, '509': 1, '510': 1, '511': 1, '512': 1, '513': 2, '514': 2, '515': 1, '516': 1, '517': 1, '518': 1, '519': 1, '520': 1, '521': 1, '522': 1, '523': 1, '524': 1, '525': 1, '526': 1, '527': 2, '528': 1, '529': 1, '530': 1, '531': 1, '532': 1, '533': 1, '534': 1, '535': 1, '536': 1, '537': 1, '538': 1, '539': 1, '540': 1, '541': 1, '542': 2, '543': 1, '544': 5, '545': 4, '546': 5, '547': 5, '548': 5, '549': 5, '550': 5, '551': 10, '552': 10, '553': 2, '554': 1, '555': 3, '556': 1, '557': 1, '558': 1, '559': 2, '560': 2, '561': 2, '562': 2, '563': 2, '564': 1, '565': 1, '566': 1, '567': 6, '568': 1, '569': 1, '570': 1, '571': 1, '572': 1, '573': 1, '574': 1, '575': 1, '576': 1, '577': 2, '578': 1, '579': 1, '580': 1, '581': 1, '582': 5, '583': 5, '584': 5, '585': 5, '586': 4, '587': 4, '588': 10, '589': 1, '590': 1, '591': 1, '592': 1, '593': 1, '594': 1, '595': 1, '596': 1, '597': 1, '598': 2, '599': 2, '600': 1, '601': 1, '602': 1, '603': 1, '604': 1, '605': 1, '606': 1, '607': 1, '608': 1, '609': 1, '610': 1, '611': 1, '612': 1, '613': 1, '614': 1, '615': 1, '616': 1, '617': 1, '618': 1, '619': 1, '620': 1, '621': 1, '622': 1, '623': 1, '624': 1, '625': 1, '626': 1, '627': 1, '628': 1, '629': 1, '630': 1, '631': 1, '632': 1, '633': 1, '634': 9, '635': 10, '636': 1, '637': 1, '638': 1, '639': 1, '640': 1, '641': 1, '642': 1, '643': 1, '644': 1, '645': 1, '647': 1, '648': 1, '649': 1, '650': 1, '651': 1, '652': 1, '653': 1, '654': 1, '655': 1, '658': 2, '659': 1, '660': 1, '661': 1, '662': 1, '663': 1, '664': 1, '665': 1, '666': 1, '667': 1, '668': 1, '669': 1, '670': 10, '671': 10}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b04f9ba083e40e9959ab7991855b7bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13353 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5660,) (5660,)\n",
            "(5660,) (657,)\n",
            "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
            " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
            " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
            " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
            " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
            " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
            " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
            " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
            " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
            " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
            " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
            " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
            " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
            " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
            " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
            " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647\n",
            " 648 649 650 651 652 653 654 655 656]\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "d={}\n",
        "labels_path = '/content/IAM_line labels/*'\n",
        "check = {}\n",
        "count = defaultdict(int)\n",
        "for filename in sorted(glob.glob(labels_path)):\n",
        "    tree = ET.parse(filename)\n",
        "    root = tree.getroot()\n",
        "    passage_id = root.attrib.get('id')\n",
        "    check[root.attrib.get('writer-id')]=check.get(root.attrib.get('writer-id'),0)+1\n",
        "\n",
        "\n",
        "for filename in sorted(glob.glob(labels_path)):\n",
        "    tree = ET.parse(filename)\n",
        "    root = tree.getroot()\n",
        "    if count[root.attrib.get('writer-id')]<1:\n",
        "   # if check[root.attrib.get('writer-id')]>=2 and count[root.attrib.get('writer-id')]<2:\n",
        "            count[root.attrib.get('writer-id')] = count.get(root.attrib.get('writer-id'),0)+1\n",
        "            for i in root.iter('line'):\n",
        "                d[i.attrib.get('id')] = root.attrib.get('writer-id')\n",
        "\n",
        "print(check)\n",
        "\n",
        "image_files = []\n",
        "ground_files = []\n",
        "images = sorted(glob.glob('/content/IAM_line images/**/*.png', recursive=True))\n",
        "\n",
        "\n",
        "\n",
        "for filename in sorted(tqdm(images)):\n",
        "    s_filename = filename\n",
        "    s_filename = s_filename.split('/')[-1]\n",
        "    s_filename = s_filename.split('.')[0]\n",
        "\n",
        "    try:\n",
        "        im = Image.open(filename)\n",
        "        if s_filename in d:\n",
        "            # im = convert_image(filename)\n",
        "            # im.save(filename,format='png')\n",
        "            image_files.append(filename)\n",
        "            ground_files.append(d[s_filename])\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "image_files = np.asarray(image_files)\n",
        "ground_files = np.asarray(ground_files)\n",
        "ground_files = LabelEncoder().fit_transform(ground_files)\n",
        "print(image_files.shape,ground_files.shape)\n",
        "print(np.unique(image_files).shape,np.unique(ground_files).shape)\n",
        "print(np.unique(ground_files))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG5xp3SytLGg"
      },
      "outputs": [],
      "source": [
        "writer = 25\n",
        "purity = 0\n",
        "num_classes_per_batch=16\n",
        "num_samples_per_class=4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqpVj3cSg712",
        "outputId": "088d20b5-2bc6-4dbe-b65f-2347169763e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(231,) (231,)\n",
            "(231,) (25,)\n"
          ]
        }
      ],
      "source": [
        "l = np.zeros((657,),dtype='int32')\n",
        "x = []\n",
        "gy = []\n",
        "\n",
        "for i in range(image_files.shape[0]):\n",
        "  if ground_files[i]<writer:\n",
        "      x.append(image_files[i])\n",
        "      gy.append(ground_files[i])\n",
        "      im = convert_image(image_files[i])\n",
        "      im.save(image_files[i],format='png')\n",
        "\n",
        "\n",
        "x = np.asarray(x)\n",
        "gy = np.asarray(gy)\n",
        "gy = LabelEncoder().fit_transform(gy)\n",
        "print(x.shape,gy.shape)\n",
        "print(np.unique(x).shape,np.unique(gy).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riK8Xh1XUV7h",
        "outputId": "c8da1138-5713-4c1a-bdef-1a664ae90b95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(231,) (231,) (231,)\n",
            "(231,) (231,) (25,)\n"
          ]
        }
      ],
      "source": [
        "def pseudo_label_assign(purity,gy):\n",
        "\n",
        "    count = np.unique(gy,return_index=True,return_counts=True)\n",
        "    counter = np.array(count[2])\n",
        "    check = np.ones((writer),dtype=np.int8)\n",
        "    py_order = []\n",
        "    py =[]\n",
        "    p=0\n",
        "    if purity == 0:\n",
        "        for i in range(gy.shape[0]):\n",
        "          py.append(p)\n",
        "          p+=1\n",
        "        py = np.asarray(py,dtype=np.int16)\n",
        "        py = LabelEncoder().fit_transform(py)\n",
        "        return py\n",
        "    for i in range(counter.shape[0]):\n",
        "\n",
        "        res = int(np.floor(counter[i]/(1/purity)))\n",
        "        remainder = int(counter[i]%(1/purity))\n",
        "        order = []\n",
        "        for k in range(int(1/purity)):\n",
        "          order.append(res)\n",
        "        for j in range(remainder):\n",
        "            order[j] +=1\n",
        "        py_order.append(order)\n",
        "\n",
        "    p=0\n",
        "    p_order =[]\n",
        "    for i in py_order:\n",
        "        for j in i:\n",
        "            p_order.append(j)\n",
        "\n",
        "    for i in range(len(p_order)):\n",
        "        for j in range(p_order[i]):\n",
        "            py.append(p)\n",
        "        p+=1\n",
        "    py = np.asarray(py,dtype=np.int16)\n",
        "    py = LabelEncoder().fit_transform(py)\n",
        "\n",
        "    return py\n",
        "\n",
        "py= pseudo_label_assign(purity=purity,gy=gy)\n",
        "\n",
        "print(x.shape,py.shape,gy.shape)\n",
        "print(np.unique(x).shape,np.unique(py).shape,np.unique(gy).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE69Aps2tP8l",
        "outputId": "9453c324-a28c-44c7-8847-96aae95d2d69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1401, 112, 224, 3) (1401,) (1401,)\n",
            "(231,) (231,) (25,)\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "img = []\n",
        "pse_label=[]\n",
        "grd_label = []\n",
        "input_shape = (112,224,1)\n",
        "def image_resize(image, width = None, height = None):\n",
        "        \"\"\"Img is a PIL image\"\"\"\n",
        "        dim = None\n",
        "        (w, h) = image.size\n",
        "\n",
        "        if width is None and height is None:\n",
        "            return None\n",
        "        if width is None:\n",
        "            r = height / float(h)\n",
        "            dim = (int(w * r), height)\n",
        "        else:\n",
        "            r = width / float(w)\n",
        "            dim = (width, int(h * r))\n",
        "\n",
        "        return image.resize(dim)\n",
        "\n",
        "for i in range(x.shape[0]):\n",
        "    im = Image.open(x[i])\n",
        "    im = image_resize(im,height=input_shape[0])\n",
        "    im = np.asarray(im,dtype=np.float32)\n",
        "    height,width = im.shape\n",
        "    # print(im.shape)\n",
        "    end_pos = 0\n",
        "    while end_pos < width-224:\n",
        "        tmp_img = im[:,end_pos:end_pos+224]\n",
        "        end_pos = end_pos+224\n",
        "        tmp = np.ones((112,224,3),dtype=np.float32)\n",
        "        tmp[...,0]=tmp_img\n",
        "        tmp[...,1]=tmp_img\n",
        "        tmp[...,2]=tmp_img\n",
        "        img.append(tmp)\n",
        "        pse_label.append(py[i])\n",
        "        grd_label.append(gy[i])\n",
        "\n",
        "# img = img[:,:,:,np.newaxis]\n",
        "X = np.asarray(img,dtype=np.uint8)\n",
        "py = np.asarray(pse_label,dtype=np.int16)\n",
        "gy = np.asarray(grd_label,dtype=np.int16)\n",
        "# x = x[:,:,:,np.newaxis]\n",
        "print(X.shape,py.shape,gy.shape)\n",
        "print(np.unique(x,axis=0).shape,np.unique(py).shape,np.unique(gy).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoYDaHfnQQ0h"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "shutil.rmtree('/content/IAM_line images')\n",
        "shutil.rmtree('/content/IAM_line labels')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_F8QOOkr3yLl"
      },
      "outputs": [],
      "source": [
        "class AEGenerator(tf.keras.utils.Sequence):\n",
        "    \"\"\" Recieves X and y\n",
        "        Performes pairwise matching with a batch size\n",
        "        both pairs are generated from the input X and y\n",
        "\n",
        "        imgs         : Input image directory\n",
        "        y            : Pseudo label, Numpy Array, Output shape=(bs, ) or (bs, 1)\n",
        "        gt           : Ground truth of the actual class, Numpy Array, Output shape=(bs, ) or (bs, 1).\n",
        "        dist      : Distance parameter for AE\n",
        "        noise     : Ratio of augmentation\n",
        "        scale     : The maximum limit of noise that would be mixed with X\n",
        "        show_logs : Show random selection errors\n",
        "\n",
        "                    Use only when show_logs is True\n",
        "\n",
        "        dg = AEGenerator(iX=X, iy=cy, dist=dist, noise=noise,\n",
        "                         batch_size=batch_size, scale=aug_scale,\n",
        "                         show_logs=False, gt=y,\n",
        "                         output_channel=1 if model == 'MobileNet' else 3)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, imgs, pseudo_label, dist, ground_label, input_shape,\n",
        "                 batch_size=64, num_classes_per_batch=16,num_samples_per_class=4, show_logs=False, prob=1.0, validation=False):\n",
        "\n",
        "        self.batch_size  = batch_size\n",
        "        self.x = imgs\n",
        "        self.py = pseudo_label\n",
        "        self.gy = ground_label\n",
        "\n",
        "        # Probability of augmentation\n",
        "        self.prob = prob\n",
        "\n",
        "        if self.py.shape[-1] == 1:\n",
        "            self.py = np.squeeze(self.py)\n",
        "        if self.gy.shape[-1] == 1:\n",
        "            self.gy = np.squeeze(self.gy)\n",
        "\n",
        "        assert len(input_shape) == 3, 'Input shape must be 3 dimentional'\n",
        "        self.input_shape = input_shape\n",
        "\n",
        "        self.total = len(self.x)\n",
        "        self.dist = dist\n",
        "\n",
        "        self.num_classes_per_batch = num_classes_per_batch\n",
        "        self.num_samples_per_class = num_samples_per_class\n",
        "\n",
        "        # Generates label : indexes_where_label_found\n",
        "        ulabels = np.unique(self.py)\n",
        "        self.class_index = dict([(label, list(np.where(self.py == label)[0])) \\\n",
        "                                 for label in ulabels])\n",
        "\n",
        "        self.indexes     = np.arange(self.total)\n",
        "        self.total_batch = self.total // self.batch_size\n",
        "        self.classes = len(ulabels)\n",
        "\n",
        "        self.rand = random.Random(12)\n",
        "        random.seed(12)\n",
        "\n",
        "        # Show logs\n",
        "        self.show_logs = show_logs\n",
        "        self.validation = validation\n",
        "        self.log = {}\n",
        "        self.on_epoch_end()\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\" Denotes the number of batches per epoch \"\"\"\n",
        "        return self.total_batch\n",
        "\n",
        "\n",
        "    def _print_logs(self):\n",
        "        for a, b in self.log.items():\n",
        "            print(a, ':', b)\n",
        "\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\" Updates indexes after each epoch \"\"\"\n",
        "        #np.random.shuffle(self.indexes)\n",
        "\n",
        "        # Shuffle class indices for all data\n",
        "        for key in self.class_index.keys():\n",
        "          np.random.shuffle(self.class_index[key])\n",
        "\n",
        "        p = 0\n",
        "        get_class = -1\n",
        "        for batch_index in range(self.__len__()):\n",
        "            # Selecting half data of same class\n",
        "            for i in range(self.batch_size//self.num_samples_per_class):\n",
        "                get_class = self._take_label(get_class)\n",
        "                for j in range(self.batch_size//self.num_classes_per_batch):\n",
        "                    self.indexes[p] = self.rand.choice(self.class_index[get_class])\n",
        "                    p += 1\n",
        "\n",
        "                # # Selecting half data of same class, different than the previous\n",
        "                # get_class = self._take_label(get_class)\n",
        "                # for j in range(self.batch_size//2):\n",
        "                #     self.indexes[p] = self.rand.choice(self.class_index[get_class])\n",
        "                #     p += 1\n",
        "\n",
        "            np.random.shuffle(self.indexes[p-self.batch_size:p])\n",
        "\n",
        "\n",
        "        if self.show_logs:\n",
        "            self._print_logs()\n",
        "            self.log['canNotLink_error'] = 0\n",
        "            self.log['time'] = 0\n",
        "\n",
        "\n",
        "\n",
        "    def _make_choice(self, p=None):\n",
        "        w = [0.5, 0.5]\n",
        "        if p is not None:\n",
        "            w = [p, 1-p]\n",
        "        return self.rand.choices([True, False], weights=w)[0]\n",
        "\n",
        "\n",
        "    def _take_label(self, avoid=-1):\n",
        "        take = avoid\n",
        "        while take == avoid:\n",
        "          take = self.rand.choice(list(self.class_index.keys()))\n",
        "        return take\n",
        "\n",
        "\n",
        "\n",
        "    def read_image(self, image_id):\n",
        "        \"\"\"Reads an image from disk, given image_id\n",
        "            Randomly crops the image w.r.t. input_shape\n",
        "        \"\"\"\n",
        "        im = Image.open(self.x[image_id])\n",
        "        # Resize the image w.r.t. aspect ratio\n",
        "        im = AEGenerator.image_resize(im, height=self.input_shape[0])\n",
        "        im = np.asarray(im, dtype=np.uint8)\n",
        "\n",
        "\n",
        "        # if self.validation:\n",
        "        #     val_im = self.line_image_mean(im)\n",
        "        #     return val_im\n",
        "\n",
        "        w_pos_l = np.random.randint(low=0, high=max(im.shape[1]-self.input_shape[1]-1, 1))\n",
        "        return im[..., w_pos_l:w_pos_l+self.input_shape[1]]\n",
        "\n",
        "\n",
        "    def _augment(self, imgs):\n",
        "        \"\"\" Inputs some image indices,\n",
        "            Returns the augmented images\n",
        "            Input_dim : [2*batch_size, ]\n",
        "        \"\"\"\n",
        "        aug_imgs = np.zeros((len(imgs), ) + self.input_shape, dtype=np.uint8)\n",
        "\n",
        "        #print('Imgs:', imgs.shape)\n",
        "        for i in range(len(imgs)):\n",
        "            aug_imgs[i] = self.aug_func(image=imgs[i])['image']\n",
        "            # print('Augmented')\n",
        "            # plt.imshow(aug_imgs[i], cmap='gray')\n",
        "            # plt.show()\n",
        "\n",
        "        return aug_imgs\n",
        "\n",
        "\n",
        "    def __getitem__(self, batch_index):\n",
        "        \"\"\" Generate one batch of data \"\"\"\n",
        "        idx, y = self._genIndexes(batch_index)\n",
        "        #img_dirs = self.x[idx]\n",
        "        # print(self.class_index)\n",
        "        # Reading the image files\n",
        "\n",
        "        imgs = np.ones((self.batch_size, ) + self.input_shape, dtype=np.uint8)\n",
        "        for i in range(self.batch_size):\n",
        "            # print(idx[i])\n",
        "            tmp_img = self.x[idx[i]]\n",
        "            imgs[i] = tmp_img\n",
        "\n",
        "\n",
        "\n",
        "        return imgs,y\n",
        "\n",
        "\n",
        "    def _genIndexes(self, index):\n",
        "        idx = np.zeros((self.batch_size), dtype=np.int16)\n",
        "        idx = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        constraint = self.py[idx]\n",
        "        # print(constraint)\n",
        "\n",
        "\n",
        "        # for i in range(self.batch_size):\n",
        "        #     plabel = self.py[idx[0][i]]\n",
        "        #     take = idx[0][i]\n",
        "\n",
        "        #     # Generating positive\n",
        "        #     idx[1][i] = self.rand.choice(self.class_index[plabel])\n",
        "        #     # Generating negative\n",
        "        #         # Taking random pair\n",
        "        #     while self.py[take] == plabel:\n",
        "        #           take = self.rand.choice(self.indexes)\n",
        "        #     constraint[i] = self.dist\n",
        "\n",
        "        #     if self.show_logs and self.gy[idx[0][i]] == self.gy[take]:\n",
        "        #         self.log['canNotLink_error'] += 1\n",
        "\n",
        "        #     idx[2][i] = take\n",
        "\n",
        "        return idx, constraint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QzYEwd8iffu"
      },
      "outputs": [],
      "source": [
        "class Distance(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    This layer is responsible for computing the distance between the anchor\n",
        "    embedding and the positive embedding, and the anchor embedding and the\n",
        "    negative embedding.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def call(self, anchor, positive, negative):\n",
        "        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
        "        # ap_distance = tf.expand_dims(tf.math.sqrt(tf.math.reduce_sum(tf.math.square(anchor-positive),\n",
        "        #                                                              axis=1)),\n",
        "                                    #  axis=-1)\n",
        "        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n",
        "        # an_distance = tf.expand_dims(tf.math.sqrt(tf.math.reduce_sum(tf.math.square(anchor-negative),\n",
        "        #                                                              axis=1)),\n",
        "                                    #  axis=-1)\n",
        "        return (ap_distance, an_distance)\n",
        "\n",
        "\n",
        "def triplet_loss_func(y_true, y_pred, mergin=0.3):\n",
        "\n",
        "\tap_distance, an_distance = y_pred[0], y_pred[1]\n",
        "\n",
        "\tloss_1 = tf.add(tf.subtract(ap_distance,an_distance), mergin)\n",
        "\tloss = tf.reduce_sum(tf.maximum(loss_1, 0.0))\n",
        "\n",
        "\treturn loss+0.03\n",
        "\n",
        "\n",
        "def buildAE(input_shape, dims, alpha=1, dis=100, topmodel = 'MobileNet',\n",
        "            scale=None, setup=0, dropout=0.001, decay=False):\n",
        "\n",
        "    inp1 = Input(input_shape, name='input1')\n",
        "    input1 = tf.keras.layers.Lambda(lambda x: (x/255.0))(inp1)\n",
        "    # inp2 = Input(input_shape, name='input2')\n",
        "    # input2 = tf.keras.layers.Lambda(lambda x: (x/255.0))(inp2)\n",
        "    # inp3 = Input(input_shape, name='input3')\n",
        "    # input3 = tf.keras.layers.Lambda(lambda x: (x/255.0))(inp3)\n",
        "\n",
        "\n",
        "    topmodel = eval(f\"{topmodel}(input_shape={input_shape},\" +\n",
        "                        \"include_top=False, weights='imagenet')\")\n",
        "\n",
        "    m = Sequential([topmodel,\n",
        "                    Flatten(),\n",
        "                    Dense(dims)], name='AutoEmbedder')\n",
        "    #m = SincNet(input_shape, dims, softmax=True)\n",
        "\n",
        "    out1 = m(input1)\n",
        "    # out2 = m(input2)\n",
        "    # out3 = m(input3)\n",
        "    out1 = tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(out1)\n",
        "\n",
        "\n",
        "\n",
        "    # Calculating distance\n",
        "    # out = Distance()(out1, out2,out3)\n",
        "\n",
        "    # Initializing model\n",
        "    # model = Model([inp1,inp2,inp3], out, name=\"AE_train\")\n",
        "    model = Model(inp1,out1,name='AE_train')\n",
        "    # Using default adam optimizer with mean square error\n",
        "    # if decay:\n",
        "    #     print('Decay loaded')\n",
        "    #     lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    #                    initial_learning_rate=0.1, decay_steps=50,\n",
        "    #                    decay_rate=0.0005)\n",
        "\n",
        "    # Optimizer default:\n",
        "    # tf.keras.optimizers.Adam(learning_rate=0.0007 if decay is False else lr_schedule)\n",
        "    model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "                  loss = tfa.losses.TripletSemiHardLoss())\n",
        "    AE = Model(inp1, out1, name=\"AutoEmbedder\")\n",
        "\n",
        "    return model, AE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwuXBIytsOXI"
      },
      "source": [
        "previous callback\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eqvo36WIsNek"
      },
      "outputs": [],
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.cluster import Birch\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "def accuracy(true_row_labels, predicted_row_labels):\n",
        "    \"\"\"Get the best accuracy.\n",
        "    Parameters\n",
        "    ----------\n",
        "    true_row_labels: array-like\n",
        "        The true row labels, given as external information\n",
        "    predicted_row_labels: array-like\n",
        "        The row labels predicted by the model\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        Best value of accuracy\n",
        "    \"\"\"\n",
        "    def _make_cost_m(cm):\n",
        "        s = np.max(cm)\n",
        "        return (- cm + s)\n",
        "\n",
        "    cm = confusion_matrix(true_row_labels, predicted_row_labels)\n",
        "    rows, columns = linear_sum_assignment(_make_cost_m(cm))\n",
        "    total = 0\n",
        "    for row, column in zip(rows, columns):\n",
        "        value = cm[row][column]\n",
        "        total += value\n",
        "\n",
        "    return (total * 1. / np.sum(cm))\n",
        "class MyLogger(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, n=1, validation_data=None,savepath=None,save_model=True,AE=None):\n",
        "        self.n = n   # print loss & acc every n epochs\n",
        "        if validation_data is not None:\n",
        "            self.x_val, self.py_val ,self.gy_val= validation_data\n",
        "            self.py_classes = len(np.unique(self.py_val))\n",
        "            self.gy_classes = len(np.unique(self.gy_val))\n",
        "        self.start_time = time.time()\n",
        "        self.start_epoch = 0\n",
        "        self.savepath=savepath\n",
        "        self.save_model = save_model\n",
        "        self.AE = AE\n",
        "\n",
        "        self.minLoss = 99999\n",
        "        self.max_K_ACC = 0\n",
        "        self.max_K_NMI = 0\n",
        "        self.max_K_ARI = 0\n",
        "\n",
        "        self.max_EM_ACC = 0\n",
        "        self.max_EM_NMI = 0\n",
        "        self.max_EM_ARI = 0\n",
        "\n",
        "        self.max_B_ACC = 0\n",
        "        self.max_B_NMI = 0\n",
        "        self.max_B_ARI = 0\n",
        "\n",
        "        self.savelog = {'Epoch': [], 'loss' : [],\n",
        "                        'K-means_PY_ACC':[], 'K-means_PY_NMI':[], 'K-means_PY_ARI':[], 'K-means_GY_ACC':[], 'K-means_GY_NMI':[], 'K-means_GY_ARI':[],\n",
        "                        'EM_PY_ACC':[], 'EM_PY_NMI':[], 'EM_PY_ARI':[], 'EM_GY_ACC':[], 'EM_GY_NMI':[], 'EM_GY_ARI':[],}\n",
        "                        #'Birch_PY_ACC':[], 'Birch_PY_NMI':[], 'Birch_PY_ARI':[], 'Birch_GY_ACC':[], 'Birch_GY_NMI':[], 'Birch_GY_ARI':[]}\n",
        "\n",
        "\n",
        "\n",
        "        if self.savepath != None:\n",
        "            self.logpath = os.path.join(self.savepath, 'log.pickle')\n",
        "            self.opti_path = os.path.join(self.savepath, 'optimizer.pkl')\n",
        "            self.modelpath = os.path.join(self.savepath, 'model_weights.h5')\n",
        "        # Creating save paths\n",
        "        if self.savepath != None and os.path.exists(self.savepath) == False:\n",
        "            os.makedirs(self.savepath)\n",
        "        # Loading previous data if found\n",
        "        if self.savepath != None and os.path.exists(self.logpath):\n",
        "            with open(self.logpath, 'rb') as f:\n",
        "                self.savelog = pickle.load(f)\n",
        "            print('Previous data loaded, starting epoch:', self.savelog['Epoch'][-1])\n",
        "            self.start_epoch = self.savelog['Epoch'][-1]\n",
        "            self.minLoss = min(self.savelog['loss'])\n",
        "\n",
        "\n",
        "            self.max_K_ACC = max(self.savelog['K-means_GY_ACC'])\n",
        "            self.max_K_NMI = max(self.savelog['K-means_GY_NMI'])\n",
        "            self.max_K_ARI = max(self.savelog['K-means_GY_ARI'])\n",
        "\n",
        "            self.max_EM_ACC = max(self.savelog['EM_GY_ACC'])\n",
        "            self.max_EM_NMI = max(self.savelog['EM_GY_NMI'])\n",
        "            self.max_EM_ARI = max(self.savelog['EM_GY_ARI'])\n",
        "\n",
        "            # self.max_B_ACC = max(self.savelog['Birch_GY_ACC'])\n",
        "            # self.max_B_NMI = max(self.savelog['Birch_GY_NMI'])\n",
        "            # self.max_B_ARI = max(self.savelog['Birch_GY_ARI'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "\n",
        "        self.start_epoch +=1\n",
        "        if self.start_epoch % self.n != 0 and self.start_epoch != 1: return\n",
        "\n",
        "\n",
        "        self.start_time = time.time()\n",
        "\n",
        "        t_k_means_acc, t_k_means_nmi, t_k_means_ari = self._KmeansAcc(self.py_classes,self.py_val)\n",
        "        v_k_means_acc, v_k_means_nmi, v_k_means_ari = self._KmeansAcc(self.gy_classes,self.gy_val)\n",
        "\n",
        "        t_em_acc, t_em_nmi, t_em_ari = self._EMG(self.py_classes,self.py_val)\n",
        "        v_em_acc, v_em_nmi, v_em_ari = self._EMG(self.gy_classes,self.gy_val)\n",
        "\n",
        "        # t_birch_acc, t_birch_nmi, t_birch_ari = self._Birch(self.py_classes,self.py_val)\n",
        "        # v_birch_acc, v_birch_nmi, v_birch_ari = self._Birch(self.gy_classes,self.gy_val)\n",
        "\n",
        "        ep_time = time.time() - self.start_time\n",
        "        print(f\"\\rEpoch {self.start_epoch}: K-means_PY_NMI {t_k_means_nmi:.5f} K-means_PY_ACC {t_k_means_acc:.5f} K-means_PY_ARI {t_k_means_ari:.5f} Time:{ep_time:.1f}\",\n",
        "              end='\\n')\n",
        "        print(f\"\\rEpoch {self.start_epoch}: K-means_GY_NMI {v_k_means_nmi:.5f} K-means_GY_ACC {v_k_means_acc:.5f} K-means_GY_ARI {v_k_means_ari:.5f} Time:{ep_time:.1f}\",\n",
        "              end='\\n')\n",
        "        print(f\"\\rEpoch {self.start_epoch}: EM_PY_NMI {t_em_nmi:.5f} EM_PY_ACC {t_em_acc:.5f} EM_PY_ARI {t_em_ari:.5f} Time:{ep_time:.1f}\",\n",
        "              end='\\n')\n",
        "        print(f\"\\rEpoch {self.start_epoch}: EM_GY_NMI {v_em_nmi:.5f} EM_GY_ACC {v_em_acc:.5f} EM_GY_ARI {v_em_ari:.5f} Time:{ep_time:.1f}\",\n",
        "              end='\\n')\n",
        "        # print(f\"\\rEpoch {self.start_epoch}: Birch_PY_NMI {t_birch_nmi:.5f} Birch_PY_ACC {t_birch_acc:.5f} Birch_PY_ARI {t_birch_ari:.5f} Time:{ep_time:.1f}\",\n",
        "        #       end='\\n')\n",
        "        # print(f\"\\rEpoch {self.start_epoch}: Birch_GY_NMI {v_birch_nmi:.5f} Birch_GY_ACC {v_birch_acc:.5f} Birch_GY_ARI {v_birch_ari:.5f} Time:{ep_time:.1f}\",\n",
        "        #       end='\\n')\n",
        "        self._saveLog(self.start_epoch, logs['loss'],\n",
        "                      t_k_means_acc, t_k_means_nmi, t_k_means_ari, v_k_means_acc, v_k_means_nmi, v_k_means_ari,\n",
        "                      t_em_acc, t_em_nmi, t_em_ari, v_em_acc, v_em_nmi, v_em_ari,)\n",
        "                      # t_birch_acc, t_birch_nmi, t_birch_ari, v_birch_acc, v_birch_nmi, v_birch_ari)\n",
        "\n",
        "        if self.savepath != None:# and logs['loss'] < self.minLoss:\n",
        "            print(f'Saving model, prev :{self.minLoss:.2f}')\n",
        "            self.minLoss = logs['loss']\n",
        "            with open(self.logpath, 'wb') as f:\n",
        "                pickle.dump(self.savelog, f)\n",
        "            if self.save_model:\n",
        "                #tf.keras.models.save_model(self.model, self.modelpath)\n",
        "                self.model.save_weights(filepath=self.modelpath, overwrite=True, )\n",
        "\n",
        "                symbolic_weights = getattr(self.model.optimizer, 'weights')\n",
        "                weight_values = K.batch_get_value(symbolic_weights)\n",
        "                with open(self.opti_path, 'wb') as f:\n",
        "                    pickle.dump(weight_values, f)\n",
        "\n",
        "        # elif self.savepath != None:\n",
        "        #     with open(self.logpath, 'wb') as f:\n",
        "        #         pickle.dump(self.savelog, f)\n",
        "\n",
        "        self.max_K_ACC = max(v_k_means_acc, self.max_K_ACC)\n",
        "        self.max_K_ARI = max(v_k_means_ari, self.max_K_ARI)\n",
        "        self.max_K_nmi = max(v_k_means_nmi, self.max_K_NMI)\n",
        "\n",
        "        self.max_EM_ACC = max(v_em_acc, self.max_EM_ACC)\n",
        "        self.max_EM_ARI = max(v_em_ari, self.max_EM_ARI)\n",
        "        self.max_EM_nmi = max(v_em_nmi, self.max_EM_NMI)\n",
        "\n",
        "        # self.max_B_ACC = max(v_birch_acc, self.max_B_ACC)\n",
        "        # self.max_B_ARI = max(v_birch_ari, self.max_B_ARI)\n",
        "        # self.max_B_nmi = max(v_birch_nmi, self.max_B_NMI)\n",
        "\n",
        "\n",
        "    def _saveLog(self, epoch, loss,t_k_means_acc, t_k_means_nmi, t_k_means_ari, v_k_means_acc, v_k_means_nmi, v_k_means_ari, t_em_acc, t_em_nmi, t_em_ari, v_em_acc, v_em_nmi, v_em_ari):#, t_birch_acc, t_birch_nmi, t_birch_ari, v_birch_acc, v_birch_nmi, v_birch_ari):\n",
        "        self.savelog['Epoch'].append(epoch)\n",
        "        self.savelog['loss'].append(loss)\n",
        "        self.savelog['K-means_PY_ACC'].append(t_k_means_acc)\n",
        "        self.savelog['K-means_PY_NMI'].append(t_k_means_nmi)\n",
        "        self.savelog['K-means_PY_ARI'].append(t_k_means_ari)\n",
        "        self.savelog['K-means_GY_ACC'].append(v_k_means_acc)\n",
        "        self.savelog['K-means_GY_NMI'].append(v_k_means_nmi)\n",
        "        self.savelog['K-means_GY_ARI'].append(v_k_means_ari)\n",
        "\n",
        "        self.savelog['EM_PY_ACC'].append(t_em_acc)\n",
        "        self.savelog['EM_PY_NMI'].append(t_em_nmi)\n",
        "        self.savelog['EM_PY_ARI'].append(t_em_ari)\n",
        "        self.savelog['EM_GY_ACC'].append(v_em_acc)\n",
        "        self.savelog['EM_GY_NMI'].append(v_em_nmi)\n",
        "        self.savelog['EM_GY_ARI'].append(v_em_ari)\n",
        "\n",
        "        # self.savelog['Birch_PY_ACC'].append(t_birch_acc)\n",
        "        # self.savelog['Birch_PY_NMI'].append(t_birch_nmi)\n",
        "        # self.savelog['Birch_PY_ARI'].append(t_birch_ari)\n",
        "        # self.savelog['Birch_GY_ACC'].append(v_birch_acc)\n",
        "        # self.savelog['Birch_GY_NMI'].append(v_birch_nmi)\n",
        "        # self.savelog['Birch_GY_ARI'].append(v_birch_ari)\n",
        "\n",
        "\n",
        "    def _EMG(self,classes,y_val):\n",
        "\n",
        "        EM = GaussianMixture(n_components=classes)\n",
        "        # AE = self.model.layers[2]\n",
        "        rindex = random.sample(range(0, y_val.shape[0]), classes*5)\n",
        "        outs = self.AE.predict(self.x_val[rindex])\n",
        "        y_pred = EM.fit_predict(outs)\n",
        "        acc = accuracy(y_val[rindex],y_pred)\n",
        "        nmi = normalized_mutual_info_score(y_val[rindex], y_pred)\n",
        "        ari = adjusted_rand_score(y_val[rindex], y_pred)\n",
        "\n",
        "        return (acc, nmi, ari)\n",
        "\n",
        "    def _Birch(self,classes,y_val):\n",
        "        birch = Birch(n_clusters=classes)\n",
        "        AE = self.model.layers[2]\n",
        "        outs = AE.predict(self.x_val)\n",
        "        y_pred = birch.fit_predict(outs)\n",
        "        acc = accuracy(y_val,y_pred)\n",
        "        nmi = normalized_mutual_info_score(y_val, y_pred)\n",
        "        ari = adjusted_rand_score(y_val, y_pred)\n",
        "\n",
        "        return (acc, nmi, ari)\n",
        "\n",
        "\n",
        "    def _KmeansAcc(self,classes,y_val):\n",
        "        kmeans = KMeans(n_clusters=classes, n_init=10)\n",
        "        #AE = self.model.layers[2]\n",
        "        rindex = random.sample(range(0, y_val.shape[0]), classes*5)\n",
        "        outs = self.AE.predict(self.x_val[rindex])\n",
        "        y_pred = kmeans.fit_predict(outs)\n",
        "        acc = accuracy(y_val[rindex], y_pred)\n",
        "        nmi = normalized_mutual_info_score(y_val[rindex], y_pred)\n",
        "        ari = adjusted_rand_score(y_val[rindex], y_pred)\n",
        "        #top_5 = top_k_accuracy_score(self.y_val[rindex],y_pred,k=5)\n",
        "\n",
        "        return (acc, nmi, ari)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkodZ4hVsfIf"
      },
      "outputs": [],
      "source": [
        "model='DenseNet121'\n",
        "dist=100\n",
        "input_shape = (112,224,3)\n",
        "dims=16\n",
        "batch_size=64\n",
        "epochs=200\n",
        "num_classes_per_batch = 16\n",
        "num_samples_per_class =4\n",
        "\n",
        "writer = 25\n",
        "line = 5\n",
        "n=5\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/UWriter_final/Triplet/logs'\n",
        "load_pretrain=False\n",
        "pretrain_path=None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiY6SL4sqgoZ",
        "outputId": "b07ac6df-3c4d-4140-add5-77acf4ac23ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Previous weights found, building model\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 0s 0us/step\n",
            "29097984/29084464 [==============================] - 0s 0us/step\n",
            "Loading weights\n",
            "Previous optimizer found,loading optimizer\n",
            "(1401, 112, 224, 3) (1401,) (1401,)\n",
            "Previous data loaded, starting epoch: 595\n",
            "Model: \"AE_train\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input1 (InputLayer)         [(None, 112, 224, 3)]     0         \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 112, 224, 3)       0         \n",
            "                                                                 \n",
            " AutoEmbedder (Sequential)   (None, 16)                7381584   \n",
            "                                                                 \n",
            " lambda_1 (Lambda)           (None, 16)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,381,584\n",
            "Trainable params: 7,297,936\n",
            "Non-trainable params: 83,648\n",
            "_________________________________________________________________\n",
            "Model: \"AutoEmbedder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet121 (Functional)    (None, 3, 7, 1024)        7037504   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 21504)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                344080    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,381,584\n",
            "Trainable params: 7,297,936\n",
            "Non-trainable params: 83,648\n",
            "_________________________________________________________________\n",
            "Starting model training\n",
            "Epoch 1/201\n",
            "21/21 [==============================] - 596s 27s/step - loss: 0.0436\n",
            "canNotLink_error : 0\n",
            "time : 0\n",
            "Epoch 2/201\n",
            "21/21 [==============================] - 547s 26s/step - loss: 0.0351\n",
            "canNotLink_error : 0\n",
            "time : 0\n",
            "Epoch 3/201\n",
            "21/21 [==============================] - 522s 25s/step - loss: 0.0360\n",
            "canNotLink_error : 0\n",
            "time : 0\n",
            "Epoch 4/201\n",
            "21/21 [==============================] - 504s 24s/step - loss: 0.0390\n",
            "canNotLink_error : 0\n",
            "time : 0\n",
            "Epoch 5/201\n",
            "Epoch 600: K-means_PY_NMI 0.99612 K-means_PY_ACC 0.97922 K-means_PY_ARI 0.97584 Time:307.3\n",
            "Epoch 600: K-means_GY_NMI 0.77474 K-means_GY_ACC 0.61600 K-means_GY_ARI 0.41953 Time:307.3\n",
            "Epoch 600: EM_PY_NMI 0.99702 EM_PY_ACC 0.98615 EM_PY_ARI 0.98411 Time:307.3\n",
            "Epoch 600: EM_GY_NMI 0.71386 EM_GY_ACC 0.54400 EM_GY_ARI 0.33460 Time:307.3\n",
            "Saving model, prev :0.03\n",
            "21/21 [==============================] - 820s 40s/step - loss: 0.0380\n",
            "canNotLink_error : 0\n",
            "time : 0\n",
            "Epoch 6/201\n",
            "21/21 [==============================] - 514s 24s/step - loss: 0.0342\n",
            "canNotLink_error : 0\n",
            "time : 0\n",
            "Epoch 7/201\n",
            "21/21 [==============================] - 501s 24s/step - loss: 0.0344\n",
            "canNotLink_error : 0\n",
            "time : 0\n",
            "Epoch 8/201\n",
            "21/21 [==============================] - 512s 24s/step - loss: 0.0304\n",
            "canNotLink_error : 0\n",
            "time : 0\n",
            "Epoch 9/201\n",
            "21/21 [==============================] - 506s 24s/step - loss: 0.0334\n",
            "canNotLink_error : 0\n",
            "time : 0\n",
            "Epoch 10/201\n",
            "Epoch 605: K-means_PY_NMI 0.99336 K-means_PY_ACC 0.96970 K-means_PY_ARI 0.95313 Time:244.6\n",
            "Epoch 605: K-means_GY_NMI 0.74355 K-means_GY_ACC 0.56800 K-means_GY_ARI 0.35083 Time:244.6\n",
            "Epoch 605: EM_PY_NMI 0.99262 EM_PY_ACC 0.96104 EM_PY_ARI 0.94584 Time:244.6\n",
            "Epoch 605: EM_GY_NMI 0.73603 EM_GY_ACC 0.56000 EM_GY_ARI 0.36325 Time:244.6\n",
            "Saving model, prev :0.04\n",
            "21/21 [==============================] - 749s 36s/step - loss: 0.0461\n",
            "canNotLink_error : 0\n",
            "time : 0\n",
            "Epoch 11/201\n",
            "21/21 [==============================] - 510s 24s/step - loss: 0.0445\n",
            "canNotLink_error : 0\n",
            "time : 0\n",
            "Epoch 12/201\n",
            "21/21 [==============================] - 511s 24s/step - loss: 0.0433\n",
            "canNotLink_error : 0\n",
            "time : 0\n",
            "Epoch 13/201\n",
            "21/21 [==============================] - 508s 24s/step - loss: 0.0323\n",
            "canNotLink_error : 0\n",
            "time : 0\n",
            "Epoch 14/201\n",
            "21/21 [==============================] - 534s 25s/step - loss: 0.0362\n",
            "canNotLink_error : 0\n",
            "time : 0\n",
            "Epoch 15/201\n",
            "Epoch 610: K-means_PY_NMI 0.99846 K-means_PY_ACC 0.99394 K-means_PY_ARI 0.99308 Time:248.1\n",
            "Epoch 610: K-means_GY_NMI 0.77862 K-means_GY_ACC 0.57600 K-means_GY_ARI 0.45692 Time:248.1\n",
            "Epoch 610: EM_PY_NMI 0.99753 EM_PY_ACC 0.98788 EM_PY_ARI 0.98493 Time:248.1\n",
            "Epoch 610: EM_GY_NMI 0.77926 EM_GY_ACC 0.59200 EM_GY_ARI 0.41239 Time:248.1\n",
            "Saving model, prev :0.05\n",
            "21/21 [==============================] - 771s 37s/step - loss: 0.0324\n",
            "canNotLink_error : 0\n",
            "time : 0\n",
            "Epoch 16/201\n",
            "21/21 [==============================] - 518s 24s/step - loss: 0.0290\n",
            "canNotLink_error : 0\n",
            "time : 0\n",
            "Epoch 17/201\n",
            "21/21 [==============================] - 527s 25s/step - loss: 0.0349\n",
            "canNotLink_error : 0\n",
            "time : 0\n",
            "Epoch 18/201\n",
            "18/21 [========================>.....] - ETA: 1:15 - loss: 0.0258"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "# def trainModel(model, X, cy, y, input_shape = (112,224,3), dist=100, dims=3, setup=2,\n",
        "#                batch_size=64, epochs=3000, writer=\"25\",line=5,\n",
        "#                load_pretrain=False, base_dir=base_dir,\n",
        "#                pretrain_path=None):\n",
        "'''\n",
        "    This would check if previously ran model exists, and load it in model and\n",
        "    AE. This function would return MyLogger callback object and the starting\n",
        "    epoch for the model. Necessary savepath parameters would be declared in this\n",
        "    function as parameter.\n",
        "\n",
        "    Possible Naming Scheme: Model_dist_dims_setup_scale_frame_[T,L,B]_MIN_SPKRs_CLIM\n",
        "    T : TIMIT\n",
        "    L : LibriSpeech\n",
        "    B : Bengali ASR\n",
        "    dist  : Distance between clusters (known as AutoEmbedder alpha parameter)\n",
        "    dims  : The output dimention of AutoEmbedder\n",
        "    frame : Frame size (input frame size)\n",
        "    scale : The scaling feature of speech (spectrogram, mfcc)\n",
        "    SPKRS : Number of speakers\n",
        "    CLIM  : Maximum Inter-cluster-linkage\n",
        "    MIN   : Minutes of speech per-speaker\n",
        "    '''\n",
        "\n",
        "strat = tf.distribute.MirroredStrategy()\n",
        "global AE\n",
        "tf.keras.backend.clear_session()\n",
        "nmodel = f\"{model}\" if model == 'MobileNet' else f\"{model}\"\n",
        "pname = f\"{nmodel}_D{dims}_W{writer}_\"\n",
        "\n",
        "loaded = False\n",
        "save_dir = os.path.join(base_dir, pname)\n",
        "opti_dir = os.path.join(save_dir,'optimizer.pkl')\n",
        "\n",
        "dg = AEGenerator(imgs=X, pseudo_label=py,\n",
        "                    dist=100, ground_label=gy, input_shape=(112, 224, 3),\n",
        "                    batch_size=batch_size, show_logs=True, validation=False,\n",
        "                    # Setting augmentation probability\n",
        "                    prob=0)\n",
        "\n",
        "    #if not os.path.exists(save_dir):\n",
        "    #    os.makedirs(save_dir)\n",
        "if os.path.exists(os.path.join(save_dir, 'model_weights.h5')):\n",
        "    try:\n",
        "        print('Previous weights found, building model')\n",
        "        # model, AE = load_AE(os.path.join(save_dir, 'model'),\n",
        "        #\n",
        "        with strat.scope():\n",
        "            model, AE = buildAE(input_shape, dims=dims,\n",
        "                                dis=100, topmodel=model)\n",
        "            print('Loading weights')\n",
        "            model.load_weights(os.path.join(save_dir, 'model_weights.h5'))\n",
        "        loaded = True\n",
        "    except Exception as e:\n",
        "        print(str(e))\n",
        "        pass\n",
        "\n",
        "    # model._make_train_function()\n",
        "    print('Previous optimizer found,loading optimizer')\n",
        "    grad_vars = model.trainable_weights\n",
        "    zero_grads = [tf.zeros_like(w) for w in grad_vars]\n",
        "    model.optimizer.apply_gradients(zip(zero_grads, grad_vars))\n",
        "    with open(opti_dir, 'rb') as f:\n",
        "      weight_values = pickle.load(f)\n",
        "    model.optimizer.set_weights(weight_values)\n",
        "\n",
        "\n",
        "\n",
        "# if not loaded and load_pretrain and pretrain_path is not None:\n",
        "#     print('Loading pre-trained model')\n",
        "#     #model, AE = load_AE(pretrain_path, dg.output_shape[1:])\n",
        "#     model, AE = buildAE(input_shape, dims=dims,\n",
        "#                             dis=100, topmodel=model)\n",
        "#     loaded = True\n",
        "\n",
        "#     model.load_weights(os.path.join(save_dir, 'model_weights.h5'))\n",
        "#     #model._make_train_function()\n",
        "#     with open(opti_dir, 'rb') as f:\n",
        "#         weight_values = pickle.load(f)\n",
        "#     model.optimizer.set_weights(weight_values)\n",
        "\n",
        "\n",
        "if not loaded:\n",
        "    print('Initializing new model')\n",
        "    with strat.scope():\n",
        "        model, AE = buildAE(input_shape, dims=dims,\n",
        "                            dis=100, topmodel=model)\n",
        "    loaded = True\n",
        "\n",
        "\n",
        "print(X.shape, py.shape, gy.shape)\n",
        "\n",
        "log = MyLogger(n,validation_data=(X,py,gy),savepath=save_dir,\n",
        "               save_model=True,AE=AE)\n",
        "\n",
        "model.summary()\n",
        "model.get_layer('AutoEmbedder').summary()\n",
        "    #time.sleep(1)\n",
        "    #AE.summary()\n",
        "\n",
        "print('Starting model training')\n",
        "model.fit(dg, epochs=epochs+1, verbose=1, callbacks=[log],)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szsI8thYHAlb"
      },
      "outputs": [],
      "source": [
        "def plotter(savelog,average,algorithm=None):\n",
        "        clear_output(wait=True)\n",
        "        plt.figure(figsize=(12.8, 4.8))\n",
        "\n",
        "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "        # dashes are the train data\n",
        "        plt.plot(savelog['Epoch'], (savelog['ACC']),\n",
        "                '--', label='tACC', c='purple')\n",
        "        plt.plot(savelog['Epoch'], (savelog['NMI']),\n",
        "                '--', label='tNMI', c='orange')\n",
        "        plt.plot(savelog['Epoch'], (savelog['ARI']),\n",
        "                '--', label='tARI', c='c')\n",
        "        # solids are validation data\n",
        "        plt.plot(savelog['Epoch'], (savelog['val_ACC']),\n",
        "                 label='ACC', c='purple')\n",
        "        plt.plot(savelog['Epoch'], (savelog['val_NMI']),\n",
        "                 label='NMI', c='orange')\n",
        "        plt.plot(savelog['Epoch'], (savelog['val_ARI']),\n",
        "                 label='ARI', c='c')\n",
        "        plt.ylabel('Score')\n",
        "        plt.xlabel('Epoch')\n",
        "\n",
        "        plt.grid()\n",
        "        plt.minorticks_on()\n",
        "        plt.grid(b=True, which='minor', linestyle='--', alpha=0.25)\n",
        "        plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.13),\n",
        "                   fancybox=True, shadow=False, ncol=5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "399717baf4564928bdff876a69f5e9d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86180fd221cf4c1bbdba2045b5ee8a0d",
            "placeholder": "​",
            "style": "IPY_MODEL_3f6b1f19800d44e182e6a98e7ff982df",
            "value": "100%"
          }
        },
        "3f6b1f19800d44e182e6a98e7ff982df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52b1cfbc85524003b37ac1d58db01f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bb382e667fe4e7e882d6287d65eab74",
            "placeholder": "​",
            "style": "IPY_MODEL_b679fe5c52b143a1916bf5dd10102583",
            "value": " 13353/13353 [00:00&lt;00:00, 274698.07it/s]"
          }
        },
        "559e1b12592a45f294ebf34dd3f7157b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b04f9ba083e40e9959ab7991855b7bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_399717baf4564928bdff876a69f5e9d1",
              "IPY_MODEL_8f418fbb15d840cbb9a99124174ec286",
              "IPY_MODEL_52b1cfbc85524003b37ac1d58db01f23"
            ],
            "layout": "IPY_MODEL_be09a1424f214254a1164d5ac15c25cd"
          }
        },
        "7bb382e667fe4e7e882d6287d65eab74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86180fd221cf4c1bbdba2045b5ee8a0d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f418fbb15d840cbb9a99124174ec286": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_559e1b12592a45f294ebf34dd3f7157b",
            "max": 13353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8b78b32a9e141fea1114a9dbe52f39e",
            "value": 13353
          }
        },
        "b679fe5c52b143a1916bf5dd10102583": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be09a1424f214254a1164d5ac15c25cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8b78b32a9e141fea1114a9dbe52f39e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}